"""
Orchestrator Agent - ƒêi·ªÅu ph·ªëi workflow gi·ªØa c√°c agent
Quy·∫øt ƒë·ªãnh g·ªçi agent n√†o d·ª±a tr√™n intent classification
"""

from agents.intent_agent import IntentClassificationAgent
from agents.sql_agent import generate_sql
from agents.viz_agent import VisualizationAgent
from agents.response_agent import ResponseAgent
from agents.analytics_agent import AnalyticsAgent
from db.connection import get_db, run_sql_unified
from langsmith.run_helpers import traceable
import pandas as pd
import time
import re


class OrchestratorAgent:
    def __init__(self, db_type: str = "postgresql"):
        self.intent_agent = IntentClassificationAgent()
        self.response_agent = ResponseAgent()
        self.viz_agent = VisualizationAgent()
        self.analytics_agent = AnalyticsAgent(db_type=db_type)
    
    @traceable(name="orchestrator.run_agent")
    def run_agent(self, user_question: str, db_type: str = "postgresql", 
                  use_retriever: bool = True, examples_path: str = "data/examples.jsonl", top_k: int = 2) -> dict:
        """
        ƒêi·ªÅu ph·ªëi workflow ch√≠nh
        
        Args:
            user_question: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
            db_type: Lo·∫°i database ("postgresql" ho·∫∑c "sqlite")
            use_retriever: C√≥ s·ª≠ d·ª•ng RAG kh√¥ng
            examples_path: ƒê∆∞·ªùng d·∫´n file examples
            top_k: S·ªë l∆∞·ª£ng examples l·∫•y t·ª´ RAG
            
        Returns:
            dict: K·∫øt qu·∫£ t·ª´ agent t∆∞∆°ng ·ª©ng
        """
        # B∆∞·ªõc 1: Ph√¢n lo·∫°i intent
        steps = []
        t0 = time.perf_counter()
        intent_result = self.intent_agent.classify_intent(user_question)
        t1 = time.perf_counter()
        steps.append({
            "step": "intent_classification",
            "duration_ms": (t1 - t0) * 1000,
            "detail": intent_result,
        })
        intent = intent_result["intent"]
        confidence = intent_result["confidence"]
        reasoning = intent_result["reasoning"]
        
        print(f"üéØ Intent: {intent} (confidence: {confidence:.2f})")
        print(f"üí≠ Reasoning: {reasoning}")
        
        # B∆∞·ªõc 2: ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn agent ph√π h·ª£p
        if intent == "query":
            return self._handle_query_intent(
                user_question, db_type, use_retriever, examples_path, top_k,
                debug_base={"intent_result": intent_result, "t_intent_ms": (t1 - t0)*1000, "steps": steps, "context": {"db_type": db_type, "examples_path": examples_path, "top_k": top_k}}
            )
        
        elif intent == "visualize":
            return self._handle_visualize_intent(
                user_question, db_type, use_retriever, examples_path, top_k,
                debug_base={"intent_result": intent_result, "t_intent_ms": (t1 - t0)*1000, "steps": steps, "context": {"db_type": db_type, "examples_path": examples_path, "top_k": top_k}}
            )
        
        
        elif intent == "schema":
            return self._handle_schema_intent(user_question, db_type)
        
        elif intent == "inventory_analytics":
            return self._handle_inventory_analytics_intent(
                user_question, db_type,
                debug_base={"intent_result": intent_result, "t_intent_ms": (t1 - t0)*1000, "steps": steps}
            )
        
        else:
            # Fallback v·ªÅ query
            return self._handle_query_intent(user_question, db_type, use_retriever, examples_path, top_k)
    
    def _handle_query_intent(self, user_question: str, db_type: str, use_retriever: bool, 
                           examples_path: str, top_k: int, debug_base: dict | None = None) -> dict:
        """X·ª≠ l√Ω query intent - SQL th√¥ng th∆∞·ªùng"""
        try:
            # Generate SQL
            if db_type == "postgresql":
                db = get_db("postgresql://inventory_user:inventory_pass@localhost:5432/inventory_db", "postgresql")
            else:
                db = get_db("data/inventory.db", "sqlite")
            t_sql0 = time.perf_counter()
            result, gen_debug = generate_sql(
                question=user_question,
                db=db,
                model="openai/gpt-oss-20b",
                examples_path=examples_path,
                top_k=top_k,
                use_semantic_search=use_retriever,
                return_debug=True,
            )
            t_sql1 = time.perf_counter()
            (debug_base or {}).get("steps", []).append({
                "step": "sql_generate",
                "duration_ms": (t_sql1 - t_sql0) * 1000,
                "detail": {"model": "openai/gpt-oss-20b"}
            })
            
            # Check if this is a schema response
            if isinstance(result, str) and "üìã **Database Schema Information**" in result:
                return {
                    "success": True,
                    "intent": "query",
                    "agent": "sql_agent",
                    "sql": "Schema Information",
                    "data": None,
                    "schema_info": result,
                    "message": "üìã Database schema information retrieved successfully!",
                    "debug": {**(debug_base or {}), "sql_generate": gen_debug},
                }
            
            if not result:
                return {
                    "success": False,
                    "error": "Unable to generate SQL query",
                    "intent": "query",
                    "agent": "sql_agent",
                    "debug": {**(debug_base or {}), "sql_generate": gen_debug},
                }
            
            # Execute SQL
            t_exec0 = time.perf_counter()
            df, error = run_sql_unified(result, db_type)
            t_exec1 = time.perf_counter()
            (debug_base or {}).get("steps", []).append({
                "step": "sql_execute",
                "duration_ms": (t_exec1 - t_exec0) * 1000,
                "detail": {"rows": 0 if error else len(df), "error": error}
            })
            if error:
                return {
                    "success": False,
                    "error": f"SQL execution error: {error}",
                    "intent": "query",
                    "agent": "sql_agent",
                    "sql": result,
                    "debug": {**(debug_base or {}), "sql_generate": gen_debug},
                }
            
            nl = self.response_agent.generate_response(user_question, df, result)
            return {
                "success": True,
                "intent": "query",
                "agent": "sql_agent",
                "sql": result,
                "data": df,
                "message": f"‚úÖ Query successful! Found {len(df)} records.",
                "response": nl.get("text"),
                "response_table_md": nl.get("table_md"),
                "debug": {
                    **(debug_base or {}),
                    "t_sql_generate_ms": (t_sql1 - t_sql0)*1000,
                    "t_sql_execute_ms": (t_exec1 - t_exec0)*1000,
                    "sql_generate": gen_debug,
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Query processing error: {str(e)}",
                "intent": "query",
                "agent": "sql_agent"
            }
    
    def _handle_visualize_intent(self, user_question: str, db_type: str, use_retriever: bool, 
                               examples_path: str, top_k: int, debug_base: dict | None = None) -> dict:
        """X·ª≠ l√Ω visualize intent - SQL + Chart"""
        try:
            # Generate SQL
            if db_type == "postgresql":
                db = get_db("postgresql://inventory_user:inventory_pass@localhost:5432/inventory_db", "postgresql")
            else:
                db = get_db("data/inventory.db", "sqlite")
            t_sql0 = time.perf_counter()
            sql, gen_debug = generate_sql(
                question=user_question,
                db=db,
                model="openai/gpt-oss-20b",
                examples_path=examples_path,
                top_k=top_k,
                use_semantic_search=use_retriever,
                return_debug=True,
            )
            t_sql1 = time.perf_counter()
            (debug_base or {}).get("steps", []).append({
                "step": "sql_generate",
                "duration_ms": (t_sql1 - t_sql0) * 1000,
                "detail": {"model": "openai/gpt-oss-20b"}
            })
            
            if not sql:
                return {
                    "success": False,
                    "error": "Unable to generate SQL query",
                    "intent": "visualize",
                    "agent": "viz_agent",
                    "debug": {**(debug_base or {}), "sql_generate": gen_debug},
                }
            
            # Execute SQL
            t_exec0 = time.perf_counter()
            df, error = run_sql_unified(sql, db_type)
            t_exec1 = time.perf_counter()
            (debug_base or {}).get("steps", []).append({
                "step": "sql_execute",
                "duration_ms": (t_exec1 - t_exec0) * 1000,
                "detail": {"rows": 0 if error else len(df), "error": error}
            })
            if error:
                return {
                    "success": False,
                    "error": f"SQL execution error: {error}",
                    "intent": "visualize",
                    "agent": "viz_agent",
                    "sql": sql,
                    "debug": {**(debug_base or {}), "sql_generate": gen_debug},
                }
            
            if df.empty:
                return {
                    "success": False,
                    "error": "No data available for chart generation",
                    "intent": "visualize",
                    "agent": "viz_agent"
                }
            
            # Plan + Render chart via agent (kh√¥ng t·∫°o summary cho visualize)
            t_viz0 = time.perf_counter()
            viz = self.viz_agent.plan_and_render(user_question, df)
            t_viz1 = time.perf_counter()
            (debug_base or {}).get("steps", []).append({
                "step": "viz_plan_render",
                "duration_ms": (t_viz1 - t_viz0) * 1000,
                "detail": viz.get("spec")
            })
            chart_result = viz.get("figure")
            
            return {
                "success": True,
                "intent": "visualize",
                "agent": "viz_agent",
                "sql": sql,
                "data": df,
                "chart": chart_result,
                "viz_spec": viz.get("spec"),
                "message": f"üìä Chart generated successfully from {len(df)} records!",
                "debug": {
                    **(debug_base or {}),
                    "t_sql_generate_ms": (t_sql1 - t_sql0)*1000,
                    "t_sql_execute_ms": (t_exec1 - t_exec0)*1000,
                    "t_viz_ms": (t_viz1 - t_viz0)*1000,
                    "sql_generate": gen_debug,
                }
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Chart generation error: {str(e)}",
                "intent": "visualize",
                "agent": "viz_agent"
            }
    
    
    
    def _handle_schema_intent(self, user_question: str, db_type: str) -> dict:
        """Handle schema intent - Database structure information"""
        try:
            from agents.sql_agent import get_schema_info
            
            if db_type == "postgresql":
                db = get_db("postgresql://inventory_user:inventory_pass@localhost:5432/inventory_db", "postgresql")
            else:
                db = get_db("data/inventory.db", "sqlite")
            schema_info = get_schema_info(db)
            
            return {
                "success": True,
                "intent": "schema",
                "agent": "schema_agent",
                "sql": "Schema Information",
                "data": None,
                "schema_info": schema_info,
                "message": "üìã Database schema information retrieved successfully!"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Schema processing error: {str(e)}",
                "intent": "schema",
                "agent": "schema_agent"
            }
    
    def _extract_top_n(self, question: str) -> int:
        """Extract 'top N' from question, default to 20"""
        # T√¨m pattern "top 10", "top 20", etc.
        match = re.search(r'\btop\s+(\d+)\b', question.lower())
        if match:
            return int(match.group(1))
        
        # N·∫øu c√≥ t·ª´ "critical" or "urgent" or "warning" -> ch·ªâ show critical/warning
        if any(word in question.lower() for word in ['critical', 'urgent', 'c·∫£nh b√°o', 'kh·∫©n c·∫•p']):
            return 10  # Default 10 for critical
        
        # Default: top 20
        return 20
    
    def _handle_inventory_analytics_intent(self, user_question: str, db_type: str, debug_base: dict | None = None) -> dict:
        """Handle inventory analytics intent - FOCUS: Stock Cover Days only"""
        try:
            question_lower = user_question.lower()
            
            # Extract top N from question
            limit = self._extract_top_n(user_question)
            
            # Calculate stock cover days
            df = self.analytics_agent.calculate_stock_cover_days()
            
            if df.empty:
                return {
                    "success": False,
                    "error": "No stock cover data available",
                    "intent": "inventory_analytics",
                    "agent": "analytics_agent"
                }
            
            # Extract threshold from question (e.g., "less than 30 days", "under 45 days")
            threshold = None
            threshold_patterns = [
                r'(?:less than|under|below|d∆∞·ªõi|nh·ªè h∆°n)\s+(\d+)\s*day',
                r'(?:greater than|above|over|tr√™n|l·ªõn h∆°n)\s+(\d+)\s*day',
            ]
            
            for pattern in threshold_patterns:
                match = re.search(pattern, question_lower)
                if match:
                    threshold = int(match.group(1))
                    is_less_than = any(word in pattern for word in ['less', 'under', 'below', 'd∆∞·ªõi', 'nh·ªè'])
                    break
            
            # Filter based on question intent
            if threshold is not None:
                # Filter by specific threshold
                if is_less_than:
                    df = df[(df['stock_cover_days'].notna()) & (df['stock_cover_days'] < threshold)]
                else:
                    df = df[(df['stock_cover_days'].notna()) & (df['stock_cover_days'] > threshold)]
            elif 'critical' in question_lower and 'warning' not in question_lower:
                # CH·ªà critical items (< 15 days)
                df = df[df['stock_status'] == 'Critical']
            elif 'warning' in question_lower or 'c·∫£nh b√°o' in question_lower:
                # Warning + Critical (< 30 days)
                df = df[df['stock_status'].isin(['Critical', 'Warning'])]
            elif 'low' in question_lower or 'lowest' in question_lower or 's·∫Øp h·∫øt' in question_lower:
                # Top N lowest stock cover (exclude No Sales)
                df = df[df['stock_status'] != 'No Sales']
            else:
                # Default: exclude "No Sales" items
                df = df[df['stock_status'] != 'No Sales']
            
            # Apply limit AFTER filtering
            df = df.head(limit)
            
            analytics_type = "stock_cover_days"
            
            if df.empty:
                return {
                    "success": False,
                    "error": "No data available for this analytics request",
                    "intent": "inventory_analytics",
                    "agent": "analytics_agent"
                }
            
            # Generate natural language summary
            nl_summary = self.analytics_agent.generate_analytics_report(user_question, df)
            
            # Add context note
            if limit < 100:
                nl_summary += f"\n\n*üí° Hi·ªÉn th·ªã top {len(df)} items (filtered). H·ªèi 'top 50' ho·∫∑c 'all' ƒë·ªÉ xem nhi·ªÅu h∆°n.*"
            
            # Generate table markdown
            table_md = None
            try:
                df_for_md = df.copy()
                for col in df_for_md.select_dtypes(include=["number"]).columns:
                    df_for_md[col] = df_for_md[col].round(2)
                table_md = df_for_md.to_markdown(index=False)
            except Exception:
                table_md = None
            
            return {
                "success": True,
                "intent": "inventory_analytics",
                "agent": "analytics_agent",
                "analytics_type": analytics_type,
                "sql": None,
                "data": df,
                "response": nl_summary,
                "response_table_md": table_md,
                "message": f"üìä Analytics completed! Generated {len(df)} insights.",
                "debug": debug_base
            }
            
        except Exception as e:
            import traceback
            return {
                "success": False,
                "error": f"Analytics processing error: {str(e)}\n{traceback.format_exc()}",
                "intent": "inventory_analytics",
                "agent": "analytics_agent"
            }
